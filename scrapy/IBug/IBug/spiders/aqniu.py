# -*- coding: utf-8 -*-
import scrapy

import requests
from lxml import etree
import json

from scrapy.http.response import Request
from IBug.items import IbugItem
from IBug.webdrivercrawler.md5 import MD5

from scrapy.selector import Selector, HtmlXPathSelector

class AqniuSpider(scrapy.Spider):
    name = 'aqniu'

    custom_settings = {
        'ROBOTSTXT_OBEY': False,
    }

    allowed_domains = ['aqniu.com']
    start_urls = ['http://www.aqniu.com/category/threat-alert']


    def parse(self, response):
        #print(response.text)

        rownodes = Selector(response=response).xpath('//div[@class="row post"]')

        # 分析每一个资讯
        for rowpost in rownodes:

            inforesult = {}

            colnode = rowpost.xpath('.//div[@class="col-md-7 col-sm-6"]')[0]

            inforesult['i_title'] = colnode.xpath('./h4/a/text()').extract_first()
            print(inforesult['i_title'])

            inforesult['i_type'] = "威胁情报"
            inforesult['i_sourcesite'] = "安全牛"

            inforesult['i_url'] = colnode.xpath('./h4/a/@href').extract_first()
            if inforesult['i_url']:
                inforesult['i_uuid'] = MD5.get_md5(inforesult['i_url'])

            inforesult['i_abstract'] = colnode.xpath('./p/text()').extract_first()

            author = colnode.xpath('.//span[@class="author"]/a/text()').extract_first()
            authorurl = colnode.xpath('.//span[@class="author"]/a/@href').extract_first()

            authordict = {'author':author, 'authorurl':authorurl}
            inforesult['i_author'] = json.dumps(authordict, ensure_ascii=False)

            # 星期三, 四月 18, 2018
            timestr = colnode.xpath('.//span[@class="date"]/text()').extract_first()
            inforesult['i_releasetime'] = self.get_info_releasetime(timestr)
            inforesult['i_content'] =  self.get_info_content(inforesult['i_url'])

            inforesult['i_imagesurls'] = rowpost.xpath('.//div[@class="thumb"]/a/img/@src').extract()

            yield IbugItem(inforesult)


        # 访问下一页
        nextpage = Selector(response=response).xpath('//div[@class="navigation"]/div[@class="nav-previous"]/a/@href').extract_first()
        if nextpage:
            print('--------------------------------------访问下一页：' + nextpage)
            yield Request(nextpage, callback=self.parse,  dont_filter=True)

    @staticmethod
    def get_info_content(url):
        html = requests.get(url=url).text
        selector = etree.HTML(html)
        contentlist = selector.xpath('//div[@class="blog-excerpt"]/*[not(div)]/descendant::text()')
        if contentlist:
            content = '\n'.join(map(lambda x: '    ' + x, contentlist))
            return content

    @staticmethod
    def get_info_releasetime(timestr):
        numdict = {'一': '1',
                   '二': '2',
                   '三': '3',
                   '四': '4',
                   '五': '5',
                   '六': '6',
                   '七': '7',
                   '八': '9',
                   '十': '10',
                   '十一': '11',
                   '十二': '12'}
        timelist = timestr.split(', ')
        day = timelist[1].split(' ')[1]
        if len(day) == 1:
            day = '0' + day

        month = numdict[timelist[1].split('月')[0]]
        if len(month) == 1:
            month = '0' + month

        year = timelist[2]
        releasetime = '%s-%s-%s' % (year, month, day)
        return releasetime