# -*- coding: utf-8 -*-

import re
import time
import json

import scrapy
from scrapy.selector import Selector, HtmlXPathSelector
from scrapy.http import Request, FormRequest, response, TextResponse

from IBug.webdrivercrawler.webParse import getParse
from IBug.webdrivercrawler.vlundatabaseparse import getVlunDatabaseParse

from IBug.webdrivercrawler.md5 import MD5
from IBug.items import IbugVulnItem


class VulnerabilitySpider(scrapy.Spider):
    name = 'vulnerability'
    allowed_domains = ['cnvd.org.cn', 'cnnvd.org.cn', 'nvd.nist.gov']
    # start_urls = ['http://ics.cnvd.org.cn/']

    cookies = {
        '__jsluid': '713a6c8c1df5082aa6ff07627a76301d',
        '__jsl_clearance': '1506217644.476|0|xIyVa%2BcEppx8ep%2F9NWWfvxR5Fgo%3D',
        'JSESSIONID': '81AAE48C645A822F7BAE59FB8828F58A',
        'bdshare_firstime': '1505890790434',
    }

    custom_settings = {
        'ROBOTSTXT_OBEY': False,
        'DEFAULT_REQUEST_HEADERS': {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Encoding': 'gzip, deflate',
        'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
        'Connection': 'keep-alive',
        },
        'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0',
        'DOWNLOAD_DELAY': 0,
        'COOKIES_DEBUG': False
    }

    count = 0
    count1 = 0

    cnvd_url = 'http://www.cnvd.org.cn'                                # cnvd地址
    cnvd_ics_url = 'http://ics.cnvd.org.cn'                            # cnvd工控系统行业漏洞目录
    cnvd_query_url = 'http://www.cnvd.org.cn/flaw/list.htm?flag=true'  # cnvd漏洞查询页面

    def start_requests(self):

        # 更新cookies
        self.cookies = getParse.getCookiesByWebDriver(url=self.cnvd_url)

        r = Request(self.cnvd_ics_url, callback=self.get_cnvd_ics_dir_start_url, cookies=self.cookies, dont_filter=False)
        yield r

        # 添加cnvd工控页面中没有的漏洞
        # r = FormRequest(self.cnvd_query_url,
        #    0             callback=self.get_cnvd_query_dir_start_url,
        #                 cookies=self.cookies,
        #                 formdata={'keyword': 'VxWorks'},
        #                 dont_filter=True)
        # yield r


    def get_cnvd_ics_dir_start_url(self, response):
        """获取cnvd工控系统行业漏洞目录页面最后一页地址，从最后一页开始爬取"""

        selector = Selector(response=response)
        pagenumstr = selector.xpath('//div[@class="pages clearfix"]/a[@class="step"][last()]/text()').extract_first()
        if pagenumstr.isnumeric():
            pagenum = int(pagenumstr)

            # 最后一页地址
            start_url = self.cnvd_ics_url + '/?max=20&offset=' + str((pagenum - 1) * 20)

            # start_url = 'http://ics.cnvd.org.cn/?max=20&offset=480'
            r = Request(start_url, callback=self.parse_cnvd_ics_dir, cookies=self.cookies, dont_filter=True)
            yield r

    def parse_cnvd_ics_dir(self, response):
        """分析cnvd工控系统行业漏洞目录页面"""

        selector = Selector(response=response)

        tdnodes = selector.xpath('//td[@style="text-align:left;padding-left:10px;"]')
        for td in tdnodes[::-1]:
            vlunurl = td.xpath('./a[@target="_blank"]/@href').extract_first()

            # vlunurl = 'http://www.cnvd.org.cn/flaw/show/CNVD-2011-5807'
            print(vlunurl)

            # 每访问8次网页，更新一次cookie
            self.count1 += 1
            if self.count1 % 8 == 0:
                print('更新cookie，此时count1为%d' % (self.count1))
                self.cookies = getParse.getCookiesByWebDriver(url='http://www.cnvd.org.cn/')

            r = Request(vlunurl, callback=self.parse_cnvd_vlun_details, cookies=self.cookies, dont_filter=True)
            # r = Request(vlunurl, callback=self.parse_detail, cookies=self.cookies, dont_filter=True)
            r.meta['big_type'] = '工控漏洞'
            yield r

        # 访问上一页
        prerelativeurl = selector.xpath('//div[@class="pages clearfix"]/a[@class="prevLink"]/@href').extract_first()
        if prerelativeurl:
            print('--------------------------------------访问上一页：' + self.cnvd_ics_url + prerelativeurl)
            r = response.follow(prerelativeurl, callback=self.parse_cnvd_ics_dir, cookies=self.cookies, dont_filter=True)
            yield r

    def parse_detail(self, response):
        """分析cnvd漏洞详情页面"""

        self.count += 1
        count = self.count
        print("count is %d" % (count))
        if response.text == '':
            print('response为空')

        basevlunresult = {}
        selector = Selector(response=response)
        basevlunresult['v_name'] = selector.xpath('//div[@class="blkContainerSblk"]/h1/text()').extract_first()
        print('漏洞名称：' + basevlunresult['v_name'])


    def parse_cnvd_vlun_details(self, response):
        # 更新cookie
        self.count += 1
        print("count is %d" % (self.count))

        basevlunresult = {}
        if response.text == '':      # 403错误处理
            selector = getParse.getSelectorByWebDriver(url=response.url)
        else:
            selector = Selector(response=response)

        try:
            basevlunresult['v_uuid'] = MD5.get_md5(response.url)
            basevlunresult['v_url'] = response.url
            basevlunresult['v_type'] = '未知'
            basevlunresult['v_threattype'] = '未知'
            basevlunresult['v_bigtype'] = response.meta['big_type']
            basevlunresult['v_updatetime'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
            basevlunresult['v_name'] = selector.xpath('//div[@class="blkContainerSblk"]/h1/text()').extract_first()
            print('漏洞名称：' + basevlunresult['v_name'])

            v_cnvds = []
            v_cves = []
            v_cnnvds = []
            v_bugtraqs = []
            v_relatedcves = []
            v_certs = []
            v_referencelinks = []
            v_impactproducts = []

            trnodes = selector.xpath('//table[@class="gg_detail"]/tbody/tr')
            for tr in trnodes[:-1]:
                td = tr.xpath('./td')
                td0Text = td[0].xpath('./text()').extract_first()

                if td0Text == 'CNVD-ID':
                    td1Text = td[1].xpath('./text()').extract_first().strip()
                    if td1Text:
                        v_cnvds.append(td1Text.strip())
                        basevlunresult['v_cnvds'] = json.dumps(v_cnvds, ensure_ascii=False)

                elif td0Text == 'CVE ID':
                    anodes = td[1].xpath('./a/text()').extract()
                    for a in anodes:
                        if ',' in a.strip():
                            for cve in a.strip().split(','):
                                v_cves.append(cve)
                        else:
                            v_cves.append(a.strip())
                    # 去除重复的CVE编号
                    if len(v_cves) > 1:
                        v_cves = list(set(v_cves))

                elif td0Text == 'BUGTRAQ ID':
                    td1Text = td[1].xpath('./a/text()').extract_first()
                    if td1Text:
                        v_bugtraqs.append(td1Text.strip())
                        basevlunresult['v_bugtraqs'] = json.dumps(v_bugtraqs, ensure_ascii=False)

                elif td0Text == '公开日期':
                    td1Text = td[1].xpath('./text()').extract_first()
                    if td1Text:
                        basevlunresult['v_releasetime'] = td1Text.strip()

                elif td0Text == '漏洞解决方案':
                    brs = td[1].xpath('./text()').extract()
                    if brs:
                        v_solution = ''
                        for br in brs[:-1]:
                            v_solution += br.strip() + '\n'
                        basevlunresult['v_solution'] = v_solution

                elif td0Text == '危害级别':
                    v_levels =td[1].xpath('./text()').extract()
                    if v_levels:
                        for v_level in v_levels:
                            if '高' in v_level:
                                basevlunresult['v_level'] = '高危'
                            elif '中' in v_level:
                                basevlunresult['v_level'] = '中危'
                            elif '低' in v_level:
                                basevlunresult['v_level'] = '低危'
                            else:
                                pass

                    v_cvssvector = td[1].xpath('./a[@class="showInfo"]/text()').extract_first()
                    if v_cvssvector:
                        basevlunresult['v_cvssvector'] = v_cvssvector

                        v_cvssstr = selector.xpath('//div[@id="showDiv"]/div[@style]/text()').extract_first()
                        v_cvsssre = re.search('[0-9.]+', v_cvssstr)
                        if v_cvsssre:
                            basevlunresult['v_cvssscore'] = float(v_cvsssre.group())

                elif td0Text == '影响产品':
                    brs = td[1].xpath('./text()').extract()
                    if brs:
                        for br in brs[:-1]:
                            v_impactproducts.append(br.strip())

                        if len(v_impactproducts):
                            basevlunresult['v_impactproducts'] = json.dumps(v_impactproducts, ensure_ascii=False)

                elif td0Text == '漏洞描述':
                    brs = td[1].xpath('./text()').extract()
                    if brs:
                        v_description = ''
                        for br in brs[:-1]:
                            v_description += br.strip() + '\n'
                        basevlunresult['v_description'] = v_description

                elif td0Text == '参考链接':
                    anodes = td[1].xpath('./a/text()').extract()
                    if anodes:
                        for a in anodes:
                            v_referencelinks.append(a)
                        if len(v_referencelinks):
                            basevlunresult['v_referencelinks'] = json.dumps(v_referencelinks, ensure_ascii=False)

                elif td0Text == '厂商补丁':
                    anode = td[1].xpath('./a')
                    if anode:
                        p_url = self.cnvd_url + anode.xpath('./@href').extract_first()
                        patchdict = getVlunDatabaseParse.get_cnvd_patch(patchurl=p_url)
                        basevlunresult.update(patchdict)
                else:
                    continue


            # 若CNVD没有CVE编号，则通过SecutiryFocus寻找CVE编号
            if len(v_bugtraqs) > 0:
                for bugtraq in v_bugtraqs:
                    cves = getVlunDatabaseParse.get_secutiryfocus_cve(bugtraqid=bugtraq)
                    if len(cves) == 1 and len(v_cves) == 0:
                        v_cves.append(cves[0])
                    elif len(cves) > 1:
                        for cve in cves:
                            v_relatedcves.append(cve)
                        basevlunresult['v_relatedcves'] = json.dumps(v_relatedcves, ensure_ascii=False)
                    else:
                        pass

            # 若存在CVE编号而且CNVD没有给出CVSS，则选用NVD网站中的CVSS分数及CVSS向量为标准值
            if len(v_cves) and basevlunresult.get('v_cvssscore') is None:
                for cve in v_cves:
                    cveTuple = getVlunDatabaseParse.get_cve_cvss(cveid=cve)
                    if cveTuple:
                        basevlunresult['v_cvssscore'] = cveTuple[0]
                         # 取其中一个CVE的CVSS信息为本漏洞信息
                        break

            if len(v_cves):
                basevlunresult['v_cves'] = json.dumps(v_cves, ensure_ascii=False)

                # 获得CNNVD编号及类型
                for cve in v_cves:
                    cnnvdTuple = getVlunDatabaseParse.get_cnnvd_id_type(cveid=cve)
                    if cnnvdTuple[0]:
                        v_cnnvds.append(cnnvdTuple[0])

                    # 若匹配到多个CVE编号，取其中一个的CNNVD类型为漏洞类型
                    if cnnvdTuple[1]:
                        basevlunresult['v_type'] = cnnvdTuple[1]

                    if cnnvdTuple[2]:
                        basevlunresult['v_threattype'] = cnnvdTuple[2]

                if len(v_cnnvds):
                    basevlunresult['v_cnnvds'] = json.dumps(v_cnnvds, ensure_ascii=False)

                # 获得CERT编号及类型
                for cve in v_cves:
                    certs = getVlunDatabaseParse.get_cert_id(cveid=cve)
                    if len(certs):
                        v_certs.extend(certs)

                if len(v_certs):
                    basevlunresult['v_certs'] = json.dumps(v_certs, ensure_ascii=False)

        except Exception as excep:
            print('parse_cnvd_vlun_details-{}出现错误：{}'.format(response.url, excep))

        finally:
            print(basevlunresult)
            yield IbugVulnItem(basevlunresult)


    def get_cnvd_query_dir_start_url(self, response):
        """获取cnvd查询页面最后一页地址，从最后一页开始爬取"""

        selector = Selector(response=response)
        anodes = selector.xpath('//div[@class="pages clearfix"]/a[@class="step"]')
        if anodes:
            for a in anodes:
                urlstr = a.xpath('./text()').extract_first()
                if urlstr:
                    # 最后一页地址
                    start_url = self.cnvd_url + urlstr

                    r = Request(start_url, callback=self.parse_cnvd_query_dir, cookies=self.cookies,
                                dont_filter=True)
                    yield r
        # 查询结果只有一页
        else:
            anodes = selector.xpath('//tbody/tr[@class]/td[@width]/a')

            for a in anodes[::-1]:
                urlstr = a.xpath('./@href').extract_first()
                if urlstr:
                    vlunurl = self.cnvd_url + urlstr
                    print(vlunurl)

                    r = Request(vlunurl, callback=self.parse_cnvd_vlun_details, cookies=self.cookies, dont_filter=True)
                    r.meta['big_type'] = '传统漏洞'
                    yield r

    def parse_cnvd_query_dir(self, response):
        """分析cnvd漏洞查询页面，搜集重要的传统漏洞"""

        selector = Selector(response=response)

        anodes = selector.xpath('//tbody/tr[@class]/td[@width]/a')
        vlunurl = ''
        for a in anodes[::-1]:
            urlstr = a.xpath('./@href').extract_first()
            if urlstr:
                vlunurl = self.cnvd_url + urlstr

            r = Request(vlunurl, callback=self.parse_cnvd_vlun_details, cookies=self.cookies, dont_filter=True)
            r.meta['big_type'] = '传统漏洞'
            yield r

        # 访问上一页
        baseurl = selector.xpath('//div[@class="pages clearfix"]/a[@class="prevLink"]/@href').extract_first()
        if baseurl:
            prepageurl = self.cnvd_url + baseurl
            print('--------------------------------------访问上一页：' + prepageurl)
            if prepageurl:
                yield Request(prepageurl, callback=self.parse_cnvd_query_dir, cookies=self.cookies, dont_filter=True)





