# -*- coding: utf-8 -*-
import scrapy
from scrapy.selector import Selector, HtmlXPathSelector

from IBug.webdrivercrawler.md5 import MD5
from IBug.items import IbugNsfocusVulnItem

import json


class NsfocusvlunSpider(scrapy.Spider):
    name = 'nsfocusvlun'
    allowed_domains = ['nsfocus.net']
    start_urls = ['http://www.nsfocus.net/index.php?act=sec_bug']

    def parse(self, response):
        selector = Selector(response=response)
        lastpageurl = selector.xpath('//div[@class="page"]/a[@class="last"]/@href').extract_first()

        # 从最后一页开始爬取
        if lastpageurl:
            r = response.follow(lastpageurl, callback=self.parse_nsfocus_vlun_dir, dont_filter=True)
            yield r


    def parse_nsfocus_vlun_dir(self, response):
        selector = Selector(response=response)
        linodes = selector.xpath('//ul[@class="vul_list"]/li')
        for li in linodes[::-1]:
            vlunurl = li.xpath('./a/@href').extract_first()
            # vlunname = li.xpath('./a/text()').extract_first()

            print(vlunurl)
            # vlunurl = 'http://www.nsfocus.net/vulndb/3457'
            if vlunurl:
                r = response.follow(vlunurl, callback=self.parse_nsfocus_vlun_details, dont_filter=True)
                yield r

        # 访问上一页
        prepageurl = selector.xpath('//div[@class="page"]/a[@class="prev"]/@href').extract_first()
        if prepageurl:
            r = response.follow(prepageurl, callback=self.parse_nsfocus_vlun_dir, dont_filter=True)
            yield r


    def parse_nsfocus_vlun_details(self, response):
        selector = Selector(response=response)
        vulbarnode = selector.xpath('//div[@class="vulbar"]')[0]

        vlunresult = {}

        n_bugtraqs = []
        n_cves = []
        n_impactsystems = ''
        n_notimpactsystems = ''

        n_description = ''
        n_recommendation = ''
        n_testmethod = ''

        if vulbarnode:
            try:
                vlunresult['n_uuid'] = MD5.get_md5(response.url)
                vlunresult['n_nsfocusid'] = int(response.url.split('/')[-1])
                vlunresult['n_name'] = vulbarnode.xpath('./div[@align="center"]/b/text()').extract_first()

                vlunresult['n_url'] = response.url

                allnodes = vulbarnode.xpath('./node()')

                for index, node in enumerate(allnodes):

                    # 发布日期
                    if node.xpath('./text()').extract_first() == '发布日期：':
                        root = allnodes[index + 1].root
                        if type(root) == str and root != '':
                            vlunresult['n_releasetime'] = root

                    # 更新日期
                    if node.xpath('./text()').extract_first() == '更新日期：':
                        root = allnodes[index + 1].root
                        if type(root) == str and root != '':
                            vlunresult['n_updatetime'] = root

                    # 受影响系统
                    if node.xpath('./text()').extract_first() == '受影响系统：':
                        subnodes = allnodes[index + 1].xpath('./node()')
                        for n in subnodes:
                            root = n.root
                            if type(root) == str and root != '':
                                n_impactsystems += root
                        if len(n_impactsystems) > 0:
                            vlunresult['n_impactsystems'] = n_impactsystems

                    # 不受影响系统
                    if node.xpath('./text()').extract_first() == '不受影响系统：':
                        subnodes = allnodes[index + 1].xpath('./node()')
                        for n in subnodes:
                            root = n.root
                            if type(root) == str and root != '':
                                n_notimpactsystems += root
                        if len(n_notimpactsystems) > 0:
                            vlunresult['n_notimpactsystems'] = n_notimpactsystems

                    # 描述
                    if node.xpath('./text()').extract_first() == '描述：':
                        i = index + 1
                        while allnodes[i].xpath('./text()').extract_first() != '测试方法：' and \
                              allnodes[i].xpath('./text()').extract_first() != '建议：':

                            # BUGTRAQ ID
                            if 'BUGTRAQ\xa0\xa0ID' in allnodes[i].root:
                                ib = i + 1
                                while allnodes[ib].root.tag == 'a':
                                    n_bugtraqs.append(allnodes[ib].xpath('./text()').extract_first())
                                    ib += 1
                                i = ib
                            # CVE(CAN) ID
                            elif 'CVE(CAN) ID' in allnodes[i].root:
                                iv = i + 1
                                while allnodes[iv].root.tag == 'a':
                                    n_cves.append(allnodes[iv].xpath('./text()').extract_first())
                                    iv += 1
                                i = iv
                            else:
                                root = allnodes[i].root
                                if type(root) == str and root != '':
                                    n_description += root
                                elif root.tag == 'a':   # 添加链接
                                    n_description += root.text
                                else:
                                    pass
                            i += 1

                        if len(n_bugtraqs) > 0:
                            vlunresult['n_bugtraqs'] = json.dumps(n_bugtraqs, ensure_ascii=False)

                        if len(n_cves) > 0:
                            vlunresult['n_cves'] = json.dumps(n_cves, ensure_ascii=False)

                        if len(n_description) > 0:
                            vlunresult['n_description'] = n_description


                    # 测试方法
                    if node.xpath('./text()').extract_first() == '测试方法：':
                        i = index + 1
                        while allnodes[i].xpath('./text()').extract_first() != '建议：':
                            root = allnodes[i].root
                            if type(root) == str and root != '':
                                n_testmethod += root
                            elif root.tag == 'a':  # 添加链接
                                n_testmethod += root.text
                            else:
                                pass
                            i += 1

                        if len(n_testmethod) > 0:
                            vlunresult['n_testmethod'] = n_testmethod

                    # 建议
                    if node.xpath('./text()').extract_first() == '建议：':
                        i = index + 1
                        while i < len(allnodes) and allnodes[i].xpath('./text()').extract_first() != '浏览次数：':
                            root = allnodes[i].root
                            if type(root) == str and root != '':
                                n_recommendation += root
                            elif root.tag == 'a':   # 添加链接
                                n_recommendation += root.text
                            else:
                                pass
                            i += 1

                        if len(n_recommendation) > 0:
                            vlunresult['n_recommendation'] = n_recommendation
            except Exception as excep:
                print('parse_nsfocus_vlun_details-{}出现错误：{}'.format(response.url, excep))

            finally:
                print(vlunresult)
                yield IbugNsfocusVulnItem(vlunresult)

